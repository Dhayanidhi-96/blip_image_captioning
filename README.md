
# ğŸ–¼ï¸ BLIP Image Captioning Web App

A simple image captioning project using the **Salesforce BLIP model** and a web interface built with **Gradio**. Upload any image and get an AI-generated caption in seconds.

---

## ğŸš€ Features

- ğŸ“Œ Image Captioning using BLIP model  
- ğŸŒ Web interface using Gradio  
- ğŸ§  Pretrained transformer model from HuggingFace  
- âš¡ Fast and easy to run locally  

---

## ğŸ“‚ Folder Structure

```
image_caption/
â”‚
â”œâ”€â”€ blip.py             # CLI test version of image captioning
â”œâ”€â”€ app.py              # Gradio web interface
â”œâ”€â”€ requirements.txt    # All dependencies
â”œâ”€â”€ README.md           # Project documentation
â””â”€â”€ venv/               # Python virtual environment (not uploaded to GitHub)
```

---

## â–¶ï¸ Run Locally

> âœ… Make sure you have **Python 3.9+** and `venv` activated

```bash
# 1. Clone the repo
git clone https://github.com/Dhayanidhi-96/blip_image_captioning.git
cd blip_image_captioning

# 2. Create virtual environment and activate
python -m venv venv

# For Windows:
venv\Scripts\activate

# For Mac/Linux:
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run the app
python app.py
```

---

## ğŸ› ï¸ Tech Stack

- Python ğŸ  
- Transformers ğŸ¤—  
- BLIP Model by Salesforce ğŸ“·  
- Gradio UI ğŸŒ  
- Pillow ğŸ–¼ï¸  

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Acknowledgements

- [Salesforce BLIP model](https://huggingface.co/Salesforce/blip-image-captioning-base)  
- [Gradio](https://www.gradio.app/)  
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/index)
